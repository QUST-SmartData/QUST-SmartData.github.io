<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SmartData</title>
    <style>
        /* è®¾ç½®æ•´ä½“å¸ƒå±€çš„å®¹å™¨ */
        .container {
            display: flex; /* ä½¿ç”¨flexå¸ƒå±€å®ç°æ°´å¹³æ’åˆ— */
/*             justify-content: space-between; /* ä½¿ä¸‰ä¸ªå—å‡åŒ€åˆ†å¸ƒ */ */
            align-items: stretch; /* ä½¿ä¸‰ä¸ªå—é«˜åº¦ä¸€è‡´ */
            width: 100%; /* å®¹å™¨å®½åº¦å æ»¡æ•´ä¸ªå±å¹• */
            padding: 10px; /* æ·»åŠ ä¸€äº›å†…è¾¹è· */
        }
        .containeravter {
            display: flex; /* ä½¿ç”¨flexå¸ƒå±€å®ç°æ°´å¹³æ’åˆ— */
/*             justify-content: space-between; /* ä½¿ä¸‰ä¸ªå—å‡åŒ€åˆ†å¸ƒ */ */
            align-items: stretch; /* ä½¿ä¸‰ä¸ªå—é«˜åº¦ä¸€è‡´ */
            flex-wrap: wrap;
            width: 100%; /* å®¹å™¨å®½åº¦å æ»¡æ•´ä¸ªå±å¹• */
            padding: 10px; /* æ·»åŠ ä¸€äº›å†…è¾¹è· */
        }

        /* è®¾ç½®æ¯ä¸ªå—çš„æ ·å¼ */
        .block {
            flex: 1; /* æ¯ä¸ªå—å æ®ç›¸ç­‰çš„ç©ºé—´ */
            margin: 0 10px; /* å—ä¹‹é—´çš„é—´è· */
            padding: 20px; /* å—å†…éƒ¨çš„é—´è· */
            border: 1px solid #ccc; /* æ·»åŠ è¾¹æ¡†ä»¥ä¾¿åŒºåˆ† */
            background-color: #f9f9f9; /* èƒŒæ™¯é¢œè‰² */
/*             max-width: 33%; */
            /*text-align: center;*/ /* æ–‡æœ¬å±…ä¸­å¯¹é½ */
        }

            /* é’ˆå¯¹ç¬¬ä¸€ä¸ªå’Œç¬¬ä¸‰ä¸ªå—çš„ç‰¹æ®Šæ ·å¼ */
            .block:first-child {
                background-color: #e6f7ff; /* ç¬¬ä¸€ä¸ªå—çš„èƒŒæ™¯é¢œè‰² */
            }

            .block:last-child {
                background-color: #ffe6e6; /* ç¬¬ä¸‰ä¸ªå—çš„èƒŒæ™¯é¢œè‰² */
            }
            /* æ–°å¢çš„é¡¶éƒ¨å—æ ·å¼ */
            .top-block {
                margin: 10px; /* æ·»åŠ ä¸€äº›å¤–è¾¹è· */
                padding: 20px; /* æ·»åŠ ä¸€äº›å†…è¾¹è· */
                border: 1px solid #ccc; /* æ·»åŠ è¾¹æ¡†ä»¥ä¾¿åŒºåˆ† */
                background-color: #f9f9f9; /* èƒŒæ™¯é¢œè‰² */
                text-align: center; /* æ–‡æœ¬å±…ä¸­å¯¹é½ */
            }
            /* åº•éƒ¨*/
            .bottom-block {
                margin: 10px; /* æ·»åŠ ä¸€äº›å¤–è¾¹è· */
                padding: 20px; /* æ·»åŠ ä¸€äº›å†…è¾¹è· */
                border: 1px solid #ccc; /* æ·»åŠ è¾¹æ¡†ä»¥ä¾¿åŒºåˆ† */
                background-color: #f9f9f9; /* èƒŒæ™¯é¢œè‰² */
                text-align: center; /* æ–‡æœ¬å±…ä¸­å¯¹é½ */
            }
            .list-item {
                margin-bottom: 10px;
            }

            .emoji {
                margin-right: 10px;
            }
        /* å¤´åƒæ ·å¼ */
        .avatar {
            width: 90%; /* å¤´åƒå®½åº¦å æ»¡å—çš„å®½åº¦ */
            height: auto; /* é«˜åº¦è‡ªåŠ¨ */
            margin-bottom: 10px; /* å¤´åƒä¸‹æ–¹çš„é—´è· */
            border-radius: 50%; /* åœ†å½¢å¤´åƒ */
            object-fit: cover; /* ç¡®ä¿å›¾ç‰‡è¦†ç›–æ•´ä¸ªå®¹å™¨ */
/*             text-align: center; */
        }

        /* å¤´åƒæ ·å¼ */
        .avatartop {
            width: 30%; /* å¤´åƒå®½åº¦å æ»¡å—çš„å®½åº¦ */
            height: auto; /* é«˜åº¦è‡ªåŠ¨ */
            margin-bottom: 10px; /* å¤´åƒä¸‹æ–¹çš„é—´è· */
            border-radius: 50%; /* åœ†å½¢å¤´åƒ */
            object-fit: cover; /* ç¡®ä¿å›¾ç‰‡è¦†ç›–æ•´ä¸ªå®¹å™¨ */
        }

        /* ä¿¡æ¯æ ·å¼ */
        .info {
            text-align: center; /* ä¿¡æ¯æ–‡æœ¬å±…ä¸­ */
        }
        .gallery {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
/*             justify-content: center; */
        }
        /* è®¾ç½®æ¯ä¸ªå¤´åƒå—çš„æ ·å¼ */
        .blockavter {
            flex: 1; /* æ¯ä¸ªå—å æ®ç›¸ç­‰çš„ç©ºé—´ */
            margin: 4px; /* å—ä¹‹é—´çš„é—´è· */
            padding: 4px; /* å—å†…éƒ¨çš„é—´è· */
            border: 1px solid #ccc; /* æ·»åŠ è¾¹æ¡†ä»¥ä¾¿åŒºåˆ† */
            background-color: #f9f9f9; /* èƒŒæ™¯é¢œè‰² */
            max-width: 20%;
            width: 20%
/*             text-align: center;*/ /* æ–‡æœ¬å±…ä¸­å¯¹é½ */
        }

            /* é’ˆå¯¹ç¬¬ä¸€ä¸ªå’Œç¬¬ä¸‰ä¸ªå—çš„ç‰¹æ®Šæ ·å¼ */
            .blockavter:first-child {
                background-color: #e6f7ff; /* ç¬¬ä¸€ä¸ªå—çš„èƒŒæ™¯é¢œè‰² */
            }
            .blockavter:second-child {
                background-color: #e6f7ff; /* ç¬¬ä¸€ä¸ªå—çš„èƒŒæ™¯é¢œè‰² */
            }

            .blockavter:last-child {
                background-color: #ffe6e6; /* ç¬¬ä¸‰ä¸ªå—çš„èƒŒæ™¯é¢œè‰² */
            }
        .gallery-image {
            width: 30%;
            height: auto;
            object-fit: contain;
            border-radius: 8px;
            transition: transform 0.3s ease;
        }
        
        .gallery-image:hover {
            transform: scale(1.05);
        }
        
        .lightbox {
            display: inline-block;
            position: relative;
            overflow: hidden;
            width: 30%;
            padding-top: 15%; /* è®¾ç½®å®½é«˜æ¯”ä¸º 2:1 */
        }
        
        .lightbox img {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
         /* åª’ä½“æŸ¥è¯¢ï¼Œä¼˜åŒ–ç§»åŠ¨è®¾å¤‡æ˜¾ç¤º */
        @media (max-width: 600px) {
            .container {
                flex-direction: column;
            }
             .gallery-image {
                width: 44%;
            }
            .lightbox {
                width: 44%;
                padding-top: 22%; /* è®¾ç½®å®½é«˜æ¯”ä¸º 2:1 */
            }
        }
        .image-container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .image-container img {
            width: 45%;
            height: auto;
            margin: 5px;
            object-fit: cover;
            cursor: pointer; /* æ·»åŠ é¼ æ ‡æ‚¬åœæ ·å¼ */
            transition: transform 0.3s ease; /* æ·»åŠ å¹³æ»‘è¿‡æ¸¡æ•ˆæœ */
        }
        .image-container img:hover {
            transform: scale(1.05); /* é¼ æ ‡æ‚¬åœæ—¶è½»å¾®æ”¾å¤§ */
        }
        .modal {
            display: none; /* é»˜è®¤éšè— */
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            overflow: auto;
            background-color: rgba(0, 0, 0, 0.7); /* åŠé€æ˜èƒŒæ™¯ */
        }
        .modal-content {
            margin: 10% auto;
            padding: 20px;
            width: 80%;
            max-width: 700px; /* æœ€å¤§å®½åº¦ */
        }
        .close {
            color: #f1f1f1;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
        }
        /* è®¿é—®ç»Ÿè®¡æ ·å¼ - ç´§å‡‘ç¾åŒ–ç‰ˆï¼ˆå“åº”å¼ä¸€è¡Œæ˜¾ç¤ºä¸”å±…ä¸­ï¼‰ */
        .flag-counter {
            position: relative;
            text-align: center;
            padding: 8px 0;
            margin-bottom: 15px;
            background: #e4e8eb;
            border-radius: 6px;
            box-shadow: 0 1px 6px rgba(0,0,0,0.05);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        .flag-counter-inner {
            display: inline-block; /* ä½¿å†…å®¹å®½åº¦è‡ªé€‚åº” */
            white-space: nowrap; /* é˜²æ­¢æ¢è¡Œ */
        }
        
        .flag-counter span {
            display: inline-block;
            margin: 0 8px;
            padding: 5px 10px;
            background: white;
            border-radius: 16px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            font-size: 13px;
            color: #555;
            transition: all 0.2s ease;
        }
        
        .flag-counter span:hover {
            transform: translateY(-1px);
            box-shadow: 0 2px 6px rgba(0,0,0,0.15);
        }
        
        .flag-counter span#vercount_value_site_pv,
        .flag-counter span#vercount_value_site_uv {
            color: #2c7be5;
            font-weight: bold;
            font-size: 14px;
        }
        
        .flag-counter::before {
            content: "";
            position: absolute;
            top: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 85%;
            height: 0.5px;
            background: linear-gradient(to right, transparent, #ddd, transparent);
        }
        
        /* ç§»åŠ¨ç«¯è°ƒæ•´ */
        @media (max-width: 600px) {
            .flag-counter {
                padding: 6px 0;
                text-align: center;
                overflow-x: auto; /* å…è®¸æ¨ªå‘æ»šåŠ¨ */
                -webkit-overflow-scrolling: touch; /* iOSå¹³æ»‘æ»šåŠ¨ */
            }
            
            .flag-counter::-webkit-scrollbar {
                display: none; /* éšè—æ»šåŠ¨æ¡ */
            }
            
            .flag-counter-inner {
                display: inline-block;
                white-space: nowrap;
                padding: 0 10px; /* æ·»åŠ å†…è¾¹è· */
            }
            
            .flag-counter span {
                margin: 0 5px;
                padding: 4px 8px;
                font-size: 12px;
            }
            
            .flag-counter span#vercount_value_site_pv,
            .flag-counter span#vercount_value_site_uv {
                font-size: 13px;
            }
        }
    </style>
</head>
<body>
    <!-- æ–°å¢çš„è®¿é—®å±•ç¤ºå…ƒç´  -->
    <div class="flag-counter">
        <div class="flag-counter-inner">
            <script defer src="https://cn.vercount.one/js"></script>
            <span>ğŸ“Š å…¨ç«™è®¿é—® <span id="vercount_value_site_pv">0</span> æ¬¡</span>
            <span>ğŸ‘¥ è®¿å®¢æ€»æ•° <span id="vercount_value_site_uv">0</span> äºº</span>
        </div>
    </div>
    <div class="top-block">
        <h1>SmartData</h1>
        <img src="logo.jpg" style="width: 50%; height: auto; margin: 5px; object-fit: contain;"/>
        <br>
        Welcome to our GitHub team homepage!
        <br>

        We aimed at studying on the artificial intellegence for the challenges on the field of studies such as geology and medicine, and solving practical problems through deep learning and computer vision technology.


        <h2 style="text-align: left;">Study</h2>
        <h3 style="text-align: left;">We focus on the following related studies:</h3>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">ğŸ–¼ï¸</span>Computer Vision
        </div>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">ğŸ§ </span>Deep Learning
        </div>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">ğŸ¤–</span>Machine Learning
        </div>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">ğŸŒ</span>IntelliSense
        </div>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">ğŸ¥</span>Medicine AI Application
        </div>
        <div class="list-item" style="text-align: left;">
            <span class="emoji">âš™ï¸</span>Industrial Applications of AI
        </div>

    </div>
    <div class="container">
        <!-- ç¬¬ä¸€ä¸ªå— -->
        <div class="block">
    
            <h2 style="text-align: left;">Contributors</h2>

<!--             <div class="container">
                <div class="block">
                    <img src="team-members/Zhaoyan Zhong.jpg" alt="Zhaoyan Zhong" class="avatar">
                    <div class="info">
                        <strong>Zhaoyan Zhong</strong><br>IntelliSense, Big model
                    </div>
                </div>
            </div> -->
            <table style="width: 100%; text-align: center;">
                <tr>
                    <td>
                        <img src="team-members/Xin%20Wang.jpg" style="width: 20%; height: auto; margin: 5px; object-fit: contain;" alt="Xin Wang" style="display: block; margin: 0 auto;" class="avatartop">
                    </td>
                </tr>
                <tr>
                    <td style="text-align: center;">
                        <strong>Supervisor: Xin Wang</strong><br>
                        Dr. Xin Wang earned his Ph.D. from China University of Petroleum (China) in 2013. He currently serves as an Associate Professor at the School of Information Science and Technology, Qingdao University of Science and Technology (China). From 2017 to 2020, he held the position of Director at the Qingdao Pore-Scale Imaging Laboratory. Concurrently, he served as a Ph.D. Supervisor at the International Graduate School of the Shandong Academy of Sciences from 2018 to 2020.  
                        <br>
                        As a visiting scholar, Dr. Wang conducted research exchanges at Imperial College London (UK), Heriot-Watt University (UK), and the Far Eastern Branch of the Russian Academy of Sciences (Russia). He participated in the Sino-Russian-Japan Joint National Scientific Expedition Team during 2016-2017. His research expertise spans 2D/3D image processing, computer vision, and artificial intelligence.  
                        
                    </td>
                </tr>
            </table>
    
            <br>
            <table style="width: 100%; text-align: center;">
                <tr>
                    <td>
                        <img src="team-members/jingsheng_ma.jpg" style="width: 20%; height: auto; margin: 5px; object-fit: contain;" alt="Xin Wang" style="display: block; margin: 0 auto;" class="avatartop">
                    </td>
                </tr>
                <tr>
                    <td style="text-align: center;">
                        <strong>Co-supervisor: Jingsheng Ma</strong><br>
                        Jingsheng Ma received his BSc degree from Lanzhou University, China, in computational mathematics, MSc degree in computing from Beijing Institute of Computer and Simulation Technology in China, and PhD in Geographical Information System from Sheffield University, UK. He joined the EGIS, Heriot-Watt University, UK, in 1997. His research interests include developing mathematical models and computational techniques for better addressing practical application problems.
                </tr>
            </table>
            <br>
<!--             <table align="center" border="1" width="100%">
                <tr>
                    <td align="center">
                        <img src="team-members/Zhaoyan Zhong.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Zhaoyan Zhong">
                    </td>
                    <td align="center">
                        <img src="team-members/Qijie Huang.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Qijie Huang">
                    </td>
                    <td align="center">
                        <img src="team-members/Xiangxin Zhao.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Xiangxin Zhao">
                    </td>
                </tr>
                <tr>
                    <td align="center">
                        <strong>Zhaoyan Zhong</strong><br>IntelliSense, Big model
                    </td>
                    <td align="center">
                        <strong>Qijie Huang</strong><br>Spacial awareness
                    </td>
                    <td align="center">
                        <strong>Xiangxin Zhao</strong><br>Unsupervised learning, Self-perception
                    </td>
                </tr>
            </table> -->

            <div class="containeravter">
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Zhaoyan Zhong.jpg" alt="Zhaoyan Zhong" class="avatar">
                    <div class="info">
                        <strong>Zhaoyan Zhong</strong><br>IntelliSense, Big model
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Qijie Huang.jpg" alt="Qijie Huang" class="avatar">
                    <div class="info">
                        <strong>Qijie Huang</strong><br>Spacial awareness
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Xiangxin Zhao.jpg" alt="Xiangxin Zhao" class="avatar">
                    <div class="info">
                        <strong>Xiangxin Zhao</strong><br>Unsupervised learning, Self-perception
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Xintao Mu.jpg" class="avatar">
                    <div class="info">
                        <strong>Xintao Mu</strong><br>Medicine AI application
                    </div>
                </div>
            </div>
            
    
            <br>

            <div class="containeravter">
                
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Yanxia Liu.jpg" class="avatar">
                    <div class="info">
                        <strong>Yanxia Liu</strong><br>Multi-scale 3D reconstruction
                    </div>
                </div>
                <div class="blockavter"style="text-align: center;">
                    <img src="team-members/Yingqi Zhang.jpg" class="avatar">
                    <div class="info">
                        <strong>Yingqi Zhang</strong><br>Latent space inversion
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Liguo Niu.jpg" class="avatar">
                    <div class="info">
                        <strong>Liguo Niu</strong><br>Super-resolution
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Xuefeng Gui.jpg" class="avatar">
                    <div class="info">
                        <strong>Xuefeng Gui</strong><br>Industrial AI application
                    </div>
                </div>
            </div>


            <br>

            <div class="containeravter">
                
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Shuyang Fan.jpg" class="avatar">
                    <div class="info">
                        <strong>Shuyang Fan</strong><br>Big model
                    </div>
                </div>
            </div>
                
                
    
<!--             <table align="center" border="1" width="100%">
                <tr>
                    <td align="center">
                        <img src="team-members/Xintao Mu.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Xintao Mu">
                    </td>
                    <td align="center">
                        <img src="team-members/Yanxia Liu.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Yanxia Liu">
                    </td>
                    <td align="center">
                        <img src="team-members/Yingqi Zhang.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Yingqi Zhang">
                    </td>
                    <td align="center">
                        <img src="team-members/Liguo Niu.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Liguo Niu">
                    </td>
                    <td align="center">
                        <img src="team-members/Xuefeng Gui.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Xuefeng Gui">
                    </td>
                    <td align="center">
                        <img src="team-members/Shuyang Fan.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Shuyang Fan">
                    </td>
                </tr>
                <tr>
                    <td align="center">
                        <strong>Xintao Mu</strong><br>Medicine AI application
                    </td>
                    <td align="center">
                        <strong>Yanxia Liu</strong><br>Multi-scale 3D reconstruction
                    </td>
                    <td align="center">
                        <strong>Yingqi Zhang</strong><br>Latent space inversion
                    </td>
                    <td align="center">
                        <strong>Liguo Niu</strong><br>Super-resolution
                    </td>
                    <td align="center">
                        <strong>Xuefeng Gui</strong><br>Industrial AI application
                    </td>
                    <td align="center">
                        <strong>Shuyang Fan</strong><br>Big model
                    </td>
                </tr>
            </table> -->
    
    
            <br>
    
            <img src="team-members/teams.jpg" style="width: 100%; height: auto; margin: 5px; object-fit: contain;" />
    
            <br>
            <br>
    
            <img src="team-members/welcome.png" style="width: 100%; height: auto; margin: 5px; object-fit: contain;" />
    
            <br>
            Graduate students of 2024

            <div class="containeravter" style="text-align: center;">
                <div class="blockavter">
                    <img src="team-members/Jia Wang.jpg" class="avatar">
                    <div class="info">
                        <strong>Jia Wang</strong>
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Jiawei Li.jpg" class="avatar">
                    <div class="info">
                        <strong>Jiawei Li</strong>
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Jialu Chen.jpg" class="avatar">
                    <div class="info">
                        <strong>Jialu Chen</strong>
                    </div>
                </div>
<!--                 <div class="blockavter" style="text-align: center;"> -->
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Lidong Zhou.jpg" class="avatar">
                    <div class="info">
                        <strong>Lidong Zhou</strong>
                    </div>
                </div>
            </div>
            <div class="containeravter">
                
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Yang Li.jpg" class="avatar">
                    <div class="info">
                        <strong>Yang Li</strong>
                    </div>
                </div>
            </div>
    
<!--             <table align="center" border="1" width="100%">
                <tr>
                    <td align="center">
                        <img src="team-members/Jia Wang.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Jia Wang">
                    </td>
                    <td align="center">
                        <img src="team-members/Jiawei Li.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Jiawei Li">
                    </td>
                    <td align="center">
                        <img src="team-members/Jialu Chen.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Jialu Chen">
                    </td>
                    <td align="center">
                        <img src="team-members/Lidong Zhou.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Lidong Zhou">
                    </td>
                    <td align="center">
                        <img src="team-members/Yang Li.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Yang Li">
                    </td>
                </tr>
                <tr>
                    <td align="center"><strong>Jia Wang</strong></td>
                    <td align="center"><strong>Jiawei Li</strong></td>
                    <td align="center"><strong>Jialu Chen</strong></td>
                    <td align="center"><strong>Lidong Zhou</strong></td>
                    <td align="center"><strong>Yang Li</strong></td>
                </tr>
            </table> -->
    
            <br>
    
            Visiting students
<!--             style="width: 50%; height: auto; margin: 5px; object-fit: contain;" -->


            <div class="containeravter">
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Ruixi Jing.jpg" class="avatar">
                    <div class="info">
                        <strong>Ruixi Jing</strong>
                    </div>
                </div>
                <div class="blockavter" style="text-align: center;">
                    <img src="team-members/Fuzhi Wan.jpg" class="avatar">
                    <div class="info">
                        <strong>Fuzhi Wan</strong>
                    </div>
                </div>
            </div>
    
<!--             <table border="1" width="100%">
                <tr>
                    <td align="center">
                        <img src="team-members/Ruixi Jing.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Ruixi Jing">
                    </td>
                    <td align="center">
                        <img src="team-members/Fuzhi Wan.jpg" style="width: 16.6667%; height: auto; margin: 5px; object-fit: contain;" alt="Fuzhi Wan">
                    </td>
                </tr>
                <tr>
                    <td align="center"><strong>Ruixi Jing</strong></td>
                    <td align="center"><strong>Fuzhi Wan</strong></td>
                </tr>
            </table> -->

            <h2 style="text-align: left;">Newsletter</h2>
            <p>Cooperation and exchange with Qilu Hospital of Shandong University in April 26, 2025</p>
            <div class="gallery">
                <a href="team-activities/4.26.jpg" class="lightbox">
                    <img src="team-activities/4.26.jpg" alt="4.26" class="gallery-image" />
                </a>
                <a href="team-activities/4.26 act.jpg" class="lightbox">
                    <img src="team-activities/4.26 act.jpg" alt="4.26 act" class="gallery-image" />
                </a>
<!--                 <a href="team-activities/Appointment Letter.jpg" class="lightbox">
                    <img src="team-activities/Appointment Letter.jpg" alt="Appointment Letter" class="gallery-image" />
                </a>
                <a href="team-activities/Appointment Letter (2).jpg" class="lightbox">
                    <img src="team-activities/Appointment Letter (2).jpg" alt="Appointment Letter (2)" class="gallery-image" />
                </a> -->
                
            </div>
            <p>Congrats!2025Spr graduated</p>
            <div class="gallery">
                <a href="team-activities/2025.5.28.jpg" class="lightbox">
                    <img src="team-activities/2025.5.28.jpg" alt="5.28" class="gallery-image" />
                </a>
                <a href="team-activities/2025.5.28(2).jpg" class="lightbox">
                    <img src="team-activities/2025.5.28(2).jpg" alt="5.28" class="gallery-image" />
                </a>
            </div>
    
            
            <h2 style="text-align: left;">Team activities</h2>
<!--             <img src="team-activities/In Aspen.jpg" alt="In Aspen" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/In HWU,Edingburg.jpg" alt="In HWU, Edingburg" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/in NTNU,Trondheim.jpg" alt="In NTNU, Trondheim" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/with Martin in ICL.jpg" alt="With Martin in ICL" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" /> 
            <img src="team-activities/å¸å›½ç†å·¥æ—¶æœŸ.jpg" alt="å¸å›½ç†å·¥æ—¶æœŸ" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/èšé¤1.jpg" alt="èšé¤1" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/èšé¤2.jpg" alt="èšé¤2" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/Joint Expedition with RAS.jpg" alt="Joint Expedition with RAS" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/In England(1).jpg" alt="In England(1)" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" />
            <img src="team-activities/In England(3).jpg" alt="In England(3)" style="width: 30%; height: auto; margin: 5px; object-fit: contain;" /> -->
            <div class="gallery">
                <a href="team-activities/In Aspen.jpg" class="lightbox">
                    <img src="team-activities/In Aspen.jpg" alt="In Aspen" class="gallery-image" />
                </a>
                <a href="team-activities/In HWU,Edingburg.jpg" class="lightbox">
                    <img src="team-activities/In HWU,Edingburg.jpg" alt="In HWU, Edingburg" class="gallery-image" />
                </a>
                <a href="team-activities/in NTNU,Trondheim.jpg" class="lightbox">
                    <img src="team-activities/in NTNU,Trondheim.jpg" alt="In NTNU, Trondheim" class="gallery-image" />
                </a>
                <a href="team-activities/with Martin in ICL.jpg" class="lightbox">
                    <img src="team-activities/with Martin in ICL.jpg" alt="With Martin in ICL" class="gallery-image" />
                </a>
                <a href="team-activities/å¸å›½ç†å·¥æ—¶æœŸ.jpg" class="lightbox">
                    <img src="team-activities/å¸å›½ç†å·¥æ—¶æœŸ.jpg" alt="å¸å›½ç†å·¥æ—¶æœŸ" class="gallery-image" />
                </a>
                <a href="team-activities/èšé¤1.jpg" class="lightbox">
                    <img src="team-activities/èšé¤1.jpg" alt="èšé¤1" class="gallery-image" />
                </a>
                <a href="team-activities/èšé¤2.jpg" class="lightbox">
                    <img src="team-activities/èšé¤2.jpg" alt="èšé¤2" class="gallery-image" />
                </a>
                <a href="team-activities/Joint Expedition with RAS.jpg" class="lightbox">
                    <img src="team-activities/Joint Expedition with RAS.jpg" alt="Joint Expedition with RAS" class="gallery-image" />
                </a>
                <a href="team-activities/In England(1).jpg" class="lightbox">
                    <img src="team-activities/In England(1).jpg" alt="In England(1)" class="gallery-image" />
                </a>
                <a href="team-activities/In England(3).jpg" class="lightbox">
                    <img src="team-activities/In England(3).jpg" alt="In England(3)" class="gallery-image" />
                </a>
                <a href="team-activities/èšä¼š3.jpg" class="lightbox">
                    <img src="team-activities/èšä¼š3.jpg" alt="èšä¼š3" class="gallery-image" />
                </a>
                <a href="team-activities/èšä¼š4.jpg" class="lightbox">
                    <img src="team-activities/èšä¼š4.jpg" alt="èšä¼š4:" class="gallery-image" />
                </a>
                <a href="team-activities/4.26.jpg" class="lightbox">
                    <img src="team-activities/4.26.jpg" alt="4.26:" class="gallery-image" />
                </a>
<!--                 <a href="team-activities/2025.3.27.jpg" class="lightbox">
                    <img src="team-activities/2025.3.27.jpg" alt="2025.3.27:" class="gallery-image" />
                </a> -->
            </div>

            <h2 style="text-align: left;">Case Study</h2>
            <h3><a href="https://github.com/QUST-SmartData/ClusterGAN">Latent Control</a></h3>
            <p><strong>Introduction</strong>: Using ClusterGAN for latent space clustering of samples enables the controlled generation of images with different properties as needed. This method combines mixed one-hot encoded variables and continuous latent variables to sample the latent space and utilizes an inverse network to map data into the latent space.</p>
             
             
            <h3>Quadruped Robot</h3>
            <div class="image-container">
                <img src="project result/robot.gif" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p5 result" onclick="openModal(this.src)" />
            </div>

            <script>
                function openModal(imageSrc) {
                    var modal = document.getElementById("myModal");
                    var modalImage = document.getElementById("modalImage");
                    modalImage.src = imageSrc; // è®¾ç½®æ”¾å¤§å›¾ç‰‡çš„æº
                    modal.style.display = "block"; // æ˜¾ç¤ºæ¨¡æ€æ¡†
                }
            
                function closeModal() {
                    var modal = document.getElementById("myModal");
                    modal.style.display = "none"; // éšè—æ¨¡æ€æ¡†
                }
            </script>
        </div>

        <!-- ç¬¬äºŒä¸ªå— -->
        <div class="block">
            <h2 style="text-align: left;">Publication</h2>
            <h3>2025:</h3>

            <h3><a href="https://github.com/QUST-SmartData/FSTI-GAN">FSTI-GAN</a></h3>
            <p><strong>Highlight</strong>: Medicine AI application</p>
            <p><strong>Title</strong>: <em>FSTI-GAN: Fusion of Structural and Textural Information (FSTI) in Generative Adversarial Network (GAN) to Improve Medical Image Inpainting</em></p>
            <p><strong>Introduction</strong>: We proposed an improved dual-stream parallel embedding network to improve the quality of image restoration by performing structural reconstruction and texture reconstruction in stages, utilizing FSTI Block to achieve global consistency of structural and texture information, and enhancing the contextual reasoning ability to effectively address the impact of poor structural and texture information on restoration results.</p>
            <p><strong>Journal</strong>: <code>Pattern Recognition, Chinese Academy of Sciences ranking Q1 (TOP), JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="http://ssrn.com/abstract=5204468">paper</a></p>

            
            <h3><a href="https://github.com/QUST-SmartData/UDAFractureSeg">UDAFractureSeg</a></h3>
            <p><strong>Highlight</strong>: Unsupervised learning</p>
            <p><strong>Title</strong>: <em>Unsupervised Domain Adaptation Based Fracture Segmentation Method for Core CT Images</em></p>
            <p><strong>Introduction</strong>: We propose an adaptive core fracture segmentation method based on unsupervised domain adaptation, which combines style migration and collaborative learning to improve the accuracy and robustness of fracture segmentation in CT images of cores from different geological sources.</p>
            <p><strong>Journal</strong>: <code>Expert Systems With Applications, Chinese Academy of Sciences ranking Q1 (TOP), JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="https://doi.org/10.1016/j.eswa.2024.125857">paper</a></p>


            <h3><a href="https://github.com/QUST-SmartData/FPEM-GAN">FPEM-GAN</a></h3>
            <p><strong>Highlight</strong>: Big model</p>
            <p><strong>Title</strong>: <em>Efficient Image Inpainting of Microresistivity Logs: A DDPM-Based Pseudo-Labeling Approach with FPEM-GAN</em></p>
            <p><strong>Introduction</strong>: We proposed a deep learning method to efficiently repair missing regions in logging images by means of pseudo-label training, perspective enhancement module and SM-Unet discriminator, which especially improves the reconstruction quality of high-angle cracks and fine-grained texture features while reducing the computational cost.</p>
            <p><strong>Journal</strong>: <code>COMPUTERS & GEOSCIENCES, Chinese Academy of Sciences ranking Q2, JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="https://doi.org/10.1016/j.cageo.2024.105812">paper</a></p>

            <h3><a href="https://github.com/QUST-SmartData/ADA-PGGAN">ADA-PGGAN</a></h3>
            <p><strong>Highlight</strong>: Latent space inversion</p>
            <p><strong>Title</strong>: <em>For Any Two Arbitrary Slices from One Digital Rock, Its Twins Can be Fast Stably Reconstructed: A Novel Integrated Model of RVION with ADA-PGGAN</em></p>
            <p><strong>Introduction</strong>: We proposed a novel feature distribution learning and adaptive data enhancement framework based on the generative model GAN, which successfully reconstructs high-quality large-scale 3D digital rocks in data-scarce environments and validates its accuracy and consistency by multiple metrics. The code is available for free, but please contact 03774@qust.edu.cn first.</p>
            <p><strong>Journal</strong>: <code>COMPUTERS & GEOSCIENCES, Chinese Academy of Sciences ranking Q2, JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0098300425000214">paper</a></p>

            

            <h3><a href="https://github.com/QUST-SmartData/DTSS">DTSS</a></h3>
            <p><strong>Highlight</strong>: Spacial awareness</p>
            <p><strong>Title</strong>: <em>A Novel Workflow of Segmentation for Finer Mineral Distingished: AttentionGAN-Swin-Transformer Fused Network</em></p>
            <p><strong>Introduction</strong>: Our proposed DTSS workflow combines AttentionGAN and Swin Transformer to achieve accurate recognition of mineral features in complex rock images through effective domain transformation and image segmentation.</p>
            <p><strong>Journal</strong>: <code>Marine and Petroleum Geology, Chinese Academy of Sciences ranking Q2 (TOP), JCR ranking Q1</code></p>
            <p><strong>Status</strong>: <code>Waiting for submission</code></p>

            <h3><a href="https://github.com/QUST-SmartData/CXRClassification">CXRClassification</a></h3>
            <p><strong>Highlight</strong>: Medicine AI application</p>
            <p><strong>Title</strong>: <em>Multi-label Chest X-ray Image Classification Based on Long-range Dependencies Capture and Label Relationships Learning</em></p>
            <p><strong>Introduction</strong>: We proposed a deep learning method combining large kernel convolutional and graph convolutional networks to improve the disease diagnosis accuracy of chest X-ray images through anatomical segmentation and label co-occurrence relations.</p>
            <p><strong>Journal</strong>: <code>Biomedical Signal Processing and Control, Chinese Academy of Sciences ranking Q2, JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="https://doi.org/10.1016/j.bspc.2024.107018">paper</a></p>

<!--             <h3><a href="https://github.com/QUST-SmartData/CXRClassification">CXRClassification</a></h3> -->
<!--             <p><strong>Highlight</strong>: Medicine AI application</p> -->
            <p><strong>Title</strong>: <em>Injecting types of mineral clays into an existing digital rock with user designing: An novel kernel algorithm embedding with 3D generative model</em></p>
<!--             <p><strong>Introduction</strong>: We proposed a deep learning method combining large kernel convolutional and graph convolutional networks to improve the disease diagnosis accuracy of chest X-ray images through anatomical segmentation and label co-occurrence relations.</p> -->
<!--             <p><strong>Journal</strong>: <code>Biomedical Signal Processing and Control, Chinese Academy of Sciences ranking Q2, JCR ranking Q1</code></p> -->
            <p><strong>Status</strong>: <code>submitted</code></p>

            <h3>2024:</h3>

            <h3><a href="https://github.com/QUST-SmartData/GeoDeepGenerativePrior">GeoDeepGenerativePrior</a></h3>
            <p><strong>Highlight</strong>: IntelliSense</p>
            <p><strong>Title</strong>: <em>Prior-Guide Adaptive Gan Method for Various Borehole Image Inpainting</em></p>
            <p><strong>Introduction</strong>: We proposed a deep learning approach that utilizes generative adversarial networks (GAN) and feature extraction fusion module to enhance the continuity and integrity of logging image restoration and effectively extract cracks, gravel structures and fine-grained texture features, thereby improving the accuracy and robustness of geologic tectonic analysis.</p>
            <p><strong>Journal</strong>: <code>GEOPHYSICS, Chinese Academy of Sciences ranking Q2 (TOP), JCR ranking Q1</code></p>
            <p><strong>Link</strong>: <a href="https://doi.org/10.1190/geo2023-0418.1">paper</a></p>

            <h3><a href="https://github.com/QUST-SmartData/DigitalRockConstruction">DigitalRockConstruction</a></h3>
            <p><strong>Highlight</strong>: Multi-scale 3D reconstruction</p>
            <p><strong>Title</strong>: <em>Integrating Sub-Scale Components Across Existing Scales in 3D Porous Media: A Novel Approach Combining Generative Artificial Intelligence Models</em></p>
            <p><strong>Introduction</strong>: We proposed a new generative modeling framework that integrates coarse- and fine-scale information through two networks to effectively model the multiscale structure of porous media and enhance the efficiency and practicality of digital rock reconstruction.</p>
            <p><strong>Journal</strong>: <code>Environmental Modelling and Software, Chinese Academy of Sciences ranking Q2, JCR ranking Q1</code></p>
            <p><strong>Status</strong>: <code>Under Review</code></p>
            
            <h3><a href="https://github.com/QUST-SmartData/FractureSeg3D">FractureSeg3D</a></h3>
            <p><strong>Highlight</strong>: Connectivity self-perception</p>
            <p><strong>Title</strong>: <em>Connectivity-Aware 3D Fracture Segmentation Method for Core CT Images</em></p>
            <p><strong>Introduction</strong>: We proposed a new fracture segmentation method for 3D core CT images, which utilizes a 3D multilayer Transformer network to capture long-range dependency and spatial continuity features, and combines dynamic weighting and multiscale context-aware fusion to significantly improve the recognition of spatial structural connectivity of fractures.</p>
            <p><strong>Journal</strong>: <code>Engineering Applications of Artificial Intelligence, Chinese Academy of Sciences ranking Q2 (TOP), JCR ranking Q1</code></p>
            <p><strong>Status</strong>: <code>Under Review</code></p>

            <h3><a href="https://github.com/QUST-SmartData/SemSR">SemSR</a></h3>
            <p><strong>Highlight</strong>: Super-resolution</p>
            <p><strong>Title</strong>: <em>A Super-resolution Framework with Semantic Guidance for Restoring Pore-Solid Interface Roughness to Enhance the Accuracy of Digital Rock Transport Properties</em></p>
            <p><strong>Introduction</strong>: We proposed a super-resolution method based on generative adversarial networks, combining semantic sharing mechanism and fuzzy noise, in order to improve the recovery of pore wall features and overcome the limitations of traditional methods when dealing with low-resolution images, thus improving the generalization ability of the model under complex geological features.</p>
            <p><strong>Journal</strong>: <code>COMPUTERS & GEOSCIENCES, Chinese Academy of Sciences ranking Q2 (TOP), JCR ranking Q1</code></p>
            <p><strong>Status</strong>: <code>Under Review</code></p>

            <h3><a href="https://github.com/QUST-SmartData/">MLDM</a></h3>
            <p><strong>Highlight</strong>: Big model</p>
            <p><strong>Title</strong>: <em>Generation of Porous Micro-structure Based on Diffusion Model</em></p>
            <p><strong>Introduction</strong>: We proposed an improved diffusion modeling network that generates rich porous structures while reducing the resolution of diffusion modeling multisamples by performing structural reconstruction and structural generation in stages, taking advantage of the dimensionality reduction capability of the self-encoder and the rich generative capability of diffusion models.</p>
            <p><strong>Journal</strong>: <code>pending</code></p>
            <p><strong>Status</strong>: <code>Manuscript Drafting</code></p>

            <h3><a href="https://github.com/QUST-SmartData/SurfaceDefectDetectionYolov8">SurfaceDefectDetectionYolov8</a></h3>
            <p><strong>Highlight</strong>: Industrial AI application</p>
            <p><strong>Title</strong>: <em>Surface defect detection method based on Deep-Learning</em></p>
            <p><strong>Introduction</strong>: In the process of small target detection, for the problem of similar defects caused by different generation mechanisms, this paper introduced a mechanism that fuses spatial attention (SA) and coordinate attention (CA). We designed a new aggregation and redistribution network model to solve the problem of small target feature loss. Meanwhile, for the boundary loss problem in small target detection, a new DOS loss function is proposed to ensure the smoothness of the small target position deviation, so as to improve the small target detection effect comprehensively.</p>
            <p><strong>Journal</strong>: <code>pending</code></p>
            <p><strong>Status</strong>: <code>Manuscript Drafting</code></p>

            

            

            <h3><a href="https://github.com/QUST-SmartData/">CLECC</a></h3>
            <p><strong>Highlight</strong>: Medicine AI application</p>
            <p><strong>Title</strong>: <em>Application of a course learning strategy based on structural prior and Ebbinghaus forgetting curve for ultrasound gallbladder lesion classification</em></p>
            <p><strong>Introduction</strong>: In ultrasound images, traditional deep learning models face challenges in classifying gallbladder lesions due to the high similarity in texture features between gallbladder tissue and surrounding soft tissue. To address this issue, this paper proposes a curriculum learning and training strategy that combines structural priors and Ebbinghaus forgetting curves. Inspired by the development of human visual acuity, we use the Relative Total Variance (RTV) method to extract structural priors from images, replacing traditional Gaussian blur processing, to more effectively separate texture and structural information, guiding the model to focus on key anatomical structural features. At the same time, a course learning strategy was designed based on the Ebbinghaus forgetting curve to optimize the learning process of the model and enhance its ability to remember and discriminate key features. The experimental results show that this method has achieved significant results in improving the accuracy and robustness of gallbladder lesion classification, providing strong support for automatic diagnosis of ultrasound images.</p>
            <p><strong>Journal</strong>: <code>IEEE Transactions on Medical Imaging, Chinese Academy of Sciences ranking Q1 (TOP), JCR ranking Q1</code></p>
            <p><strong>Status</strong>: <code>Waiting for submission</code></p>
        </div>

        <!-- ç¬¬ä¸‰ä¸ªå— -->
        <div class="block">
            <h2 style="text-align: left;">Projects</h2>
            This category includes industrial application projects related to AI models, focusing on process automation, innovation driven solutions, and customer experience enhancement.
            <h3><a href="https://github.com/QUST-SmartData/AICAD">AI based municipal design software assisted system</a></h3>
            <p><strong>Introduction</strong>: This project aims to improve the efficiency and accuracy of municipal design by introducing AI technology on top of existing municipal design software in order to realize intelligent drawing functions in municipal design tasks. The project includes conducting a detailed requirements analysis, introducing applicable AI technologies, researching and training AI models, developing and integrating the software, as well as summarizing the project and accepting the results.</p>
            <h4>Goals</h4>
            <ul>
                <li>Intersection Identification and Intelligent Splitting: Accurately identify key road intersections in the software design drawings through AI technology, and design reasonable and efficient splitting schemes to realize drawing division.</li>
                <li>Batch Replacement of Drawing Frames: Automatically replace drawing frames in batch to simplify manual processing.</li>
                <li>Text input automation: automate the text input process to reduce the time-consuming manual operation.</li>
                <li>Batch printing: realize batch printing of design drawings to further improve work efficiency.</li>
            </ul>
            <h4>Results</h4>
            <div class="image-container">
                <img src="project result/AICAD1.png" alt="split" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)"/> 
                <img src="project result/AICAD2.png" alt="split" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)"/> 
                <img src="project result/AICAD3.png" alt="split" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)"/> 
                <img src="project result/split.gif" alt="split" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)"/> 
            </div>
            <br>
            

            <h3>Study on the performance of bone cement implant repair materials in mouse femoral structures</h3>
            <p><strong>Introduction</strong>: This project uses the mouse femur as a model, and systematically studies the degradation of bone cement, new bone growth, and changes in bone tissue structure at different time points (one month and three months) by implanting bone cement of different materials. Through data visualization and multi-parameter analysis, including pore size distribution, coordination number, shape factor, and tortuosity, the dynamic changes of bone cement implants in the in vivo environment and their impact on bone tissue repair are revealed.</p>
            <h4>Results</h4>
            <p>The image shows the data visualization changes of the structure of the mouse femur and the bone cement implant at one month (left 1, left 2) and three months (right 1, right 2).</p>
<!--             <div style="display: flex; justify-content: space-between; align-items: center;">
                <img src="project result/one month.png" alt="one month" style="width: 45%; height: auto; margin: 5px; object-fit: cover;" />
                <img src="project result/three month.png" alt="three month" style="width: 45%; height: auto; margin: 5px; object-fit: cover;" />
            </div> -->
            <div class="image-container">
                <img src="project result/one month.png" alt="one month" style="width: 22%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)" />
                <img src="project result/one month2.png" alt="one month2" style="width: 22%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)" />
                <img src="project result/three month.png" alt="three month" style="width: 22%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)" />
                <img src="project result/three month2.png" alt="three month2" style="width: 22%; height: auto; margin: 5px; object-fit: cover;" onclick="openModal(this.src)" />
            </div>
            <br>
            
            
            <h3><a href="https://github.com/QUST-SmartData/Research-on-spatial-structure-reconstruction-of-3D-core-fracture-model">Research on spatial structure reconstruction of 3D core fracture model</a></h3>
            <p><strong>cooperating organization</strong>: Institute of Finance and Economics, China University of Petroleum</p>
            <p><strong>Introduction</strong>: This project aims to develop advanced techniques for the reconstruction of three-dimensional rock fracture models based on extracted information from real fracture characteristics. By integrating statistical analysis, numerical simulation, and advanced imaging techniques, we strive to create realistic fracture models that can accurately represent the spatial distribution, aperture variation, and morphological features of natural fractures. The research focuses on several key aspects, including the regeneration of fracture aperture based on Gaussian distribution approximations, the reconstruction of fracture morphology considering real dimensions, orientation, and anisotropy, and the fusion of regenerated fractures to form coherent three-dimensional networks.</p>
<!--             <h4>Reconstruction process</h4> -->
<!--             <div class="image-container">
                <img src="project result/reconstruction process.png" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="reconstruction results1" onclick="openModal(this.src)" />
            </div> -->
            <h4>Reconstruction results</h4>
            <div class="image-container">
                <img src="project result/reconstruction results1.png" alt="reconstruction results1" onclick="openModal(this.src)" />
                <img src="project result/reconstruction results2.png" alt="reconstruction results2" onclick="openModal(this.src)" />
            </div>
            <br>

            <h3><a href="https://github.com/QUST-SmartData/CXRClassification">Chest X-ray Disease Diagnosis and Classification System</a></h3>
<!--             <p><strong>cooperating organization</strong>: Qilu Hospital of Shandong University</p> -->
            <p><strong>Introduction</strong>: The detection of chest diseases from chest X-ray images using deep learning methods has been an active research area over the past decade. The diagnosis of chest diseases depends largely on the decision-making of radiologists. In the context of a severe shortage of professional radiologists, it is very important to develop automatic analysis methods for computer-aided diagnosis of chest diseases on chest radiographs. By integrating attention mechanisms into deep learning models, many previous methods have shown significant improvements in automatic disease classification. However, existing methods focus on using small-scale spatial attention and often ignore larger-scale image context information associations. Based on this, the system developed by the research team proposes a large-scale attention-based chest disease classification network that is able to consider larger-scale attention-guided spatial features, has a concise network structure and fewer model parameters. In addition, it captures the detailed features of the region of interest through anatomical segmentation and uses graph convolutional networks (GCNs) to establish potential relationships between different diseases. This system can be used in the field of chest X-ray disease classification as an auxiliary tool for early diagnosis of diseases in clinical practice.</p>
<!--             <h4>Method Architecture</h4>
            <div class="image-container">
                <img src="project result/p4 methods.png" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p4 methods" onclick="openModal(this.src)" />
            </div> -->
            <h4>Diagnostic results</h4>
            <div class="image-container">
                <img src="project result/p4 result.png" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p4 result" onclick="openModal(this.src)" />
            </div>
            <br>

            <h3><a href="https://github.com/QUST-SmartData/Lymphocyte-tissue-identification-and-3D-reconstruction">Lymphocyte tissue identification and 3D reconstruction</a></h3>
            <p><strong>cooperating organization</strong>: Ningbo No.2 People's Hospital</p>
            <p><strong>Introduction</strong>: Conventional CT two-dimensional images have the limitation of insufficient spatial perception when displaying lesion characteristics. The three-dimensional reconstruction imaging technology is based on high-quality cross-sectional scanning images, combined with medical imaging, computer image processing and biomedical engineering and other multi-field technologies, and can observe the lesions from multiple angles as a whole, providing an important basis for disease diagnosis and preoperative planning. Through three-dimensional reconstruction, doctors can move, rotate, and make transparent the three-dimensional model before surgery, intuitively understand the location of the lesion and its spatial relationship with the surrounding tissues, and combine virtual reality technology to simulate surgery, optimize surgical plans, reduce surgical risks, and improve surgical accuracy and success rate. In simulated surgery, artificial intelligence technology is used to segment the lesion tissue from the two-dimensional slices, and then accurately locate it through three-dimensional reconstruction technology, clearly display the relative position of the lesion tissue and bones or normal organs, and provide scientific support for surgical planning. We first use artificial intelligence technology to segment the lesion tissue from the two-dimensional slice information, and then reconstruct the lesion tissue through three-dimensional reconstruction technology, and accurately locate it to the original position, so that the relative position between the lesion tissue and bones or normal organs can be clearly displayed.</p>
<!--             <h4>Method Architecture</h4> -->
<!--             <div class="image-container">
                <img src="project result/p5 methods.png" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p5 methods" onclick="openModal(this.src)" />
            </div> -->
            <h4>Reconstruction result</h4>
            <div class="image-container">
                <img src="project result/p5 result.gif" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p5 result" onclick="openModal(this.src)" />
            </div>
            <br>

            <h3><a href="https://github.com/QUST-SmartData/Gallbladder-ultrasound-image-classification">Gallbladder ultrasound image classification</a></h3>
            <p><strong>Collaborating organization</strong>: Qilu Hospital of Shandong University</p>
            <p><strong>Introduction</strong>: AI has made great progress in the field of medical image analysis, providing new possibilities for the automated diagnosis of gallbladder cancer. Deep learning methods, especially those based on convolutional neural networks (CNNs), have shown excellent performance in gallbladder cancer detection, and can automatically extract complex features in medical images and identify subtle lesion patterns, thereby improving the accuracy of diagnosis. Researchers have proposed a variety of deep learning-based gallbladder cancer detection methods, such as the region selection network combined with a multi-scale second-order pooling classifier (MS-SoP), the application of Mask R-CNN in gallstone detection, and a gallbladder detection method combining YOLO and Faster R-CNN. These methods have made positive progress in optimizing detection boundaries and improving classification accuracy. However, current research still faces many challenges, including the scarcity of datasets, the problem of co-optimization of target detection and classification networks, and the impact of low quality and noise interference of ultrasound images on the model. To address these issues, the research team collected and annotated a dataset of 368 ultrasound images to make up for the lack of data. In addition, the team conducted a systematic comparative analysis of existing target detection methods and proposed a structure-aware curriculum learning strategy, which combines relative total variation and label smoothing techniques to gradually train the model from simple structures to complex textures, making it more focused on key structural features and improving the robustness and generalization ability of gallbladder cancer detection.</p>
            
<!--             <h4>Method Architecture</h4> -->
<!--             <div class="image-container">
                <img src="project result/p6 method.jpg" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p5 methods" onclick="openModal(this.src)" />
            </div> -->
            <h4>Diagnosis result</h4>
            <div class="image-container">
                <img src="project result/p6 result.jpg" style="width: 100%; height: auto; margin: 5px; object-fit: cover;" alt="p5 result" onclick="openModal(this.src)" />
            </div>
            <br>

            <div id="myModal" class="modal">
                <div class="modal-content">
                    <span class="close" onclick="closeModal()">&times;</span>
                    <img id="modalImage" src="" alt="Zoomed Image" style="width: 100%; height: auto;" />
                </div>
            </div>

            <script>
                function openModal(imageSrc) {
                    var modal = document.getElementById("myModal");
                    var modalImage = document.getElementById("modalImage");
                    modalImage.src = imageSrc; // è®¾ç½®æ”¾å¤§å›¾ç‰‡çš„æº
                    modal.style.display = "block"; // æ˜¾ç¤ºæ¨¡æ€æ¡†
                }
            
                function closeModal() {
                    var modal = document.getElementById("myModal");
                    modal.style.display = "none"; // éšè—æ¨¡æ€æ¡†
                }
            </script>

        </div>
    </div>
    <div class="bottom-block">
        <h2 style="text-align: left;">Language and Tools</h2>
        <p>
            <img width="30%" src="https://www.vectorlogo.zone/logos/python/python-ar21.svg" alt="Python">
            <img width="30%" src="https://www.vectorlogo.zone/logos/numpy/numpy-ar21.svg" alt="NumPy">
            <img width="30%" src="https://www.vectorlogo.zone/logos/opencv/opencv-ar21.svg" alt="OpenCV">

            <br />
            <img width="30%" src="https://www.vectorlogo.zone/logos/pytorch/pytorch-ar21.svg" alt="PyTorch">
            <img width="30%" src="https://www.vectorlogo.zone/logos/tensorflow/tensorflow-ar21.svg" alt="TensorFlow">
            <img width="30%" src="https://www.vectorlogo.zone/logos/jupyter/jupyter-ar21.svg" alt="Jupyter">
            <br />
            <img width="30%" src="https://www.vectorlogo.zone/logos/git-scm/git-scm-ar21.svg" alt="Git">
            <img width="30%" src="https://www.vectorlogo.zone/logos/github/github-ar21.svg" alt="GitHub">
            <img width="30%" src="https://www.vectorlogo.zone/logos/visualstudio_code/visualstudio_code-ar21.svg" alt="VS Code">
        </p>

        <h2 style="text-align: left;">Statistical Information</h2>
        <img width="85%" src="https://github-readme-stats.vercel.app/api?username=QUST-SmartData&theme=ambient_gradient&show_icons=true&hide_border=true" alt="GitHub Stats">
        <br />
        <img width="85%" src="https://github-readme-stats.vercel.app/api/top-langs/?username=QUST-SmartData&hide=jupyter%20notebook&show_icons=true&hide_border=true&layout=donut&theme=ambient_gradient" alt="Top Languages">

        <!--   è®¿é—®åœ°å›¾   -->
        <div style="text-align: center;">
            <a href="http://s05.flagcounter.com/more/FyXh">
                <img width="85%" src="https://s05.flagcounter.com/map/FyXh/size_l/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="è®¿å®¢åœ°å›¾" border="0">
            </a>
        </div>
        
        <h2 style="text-align: left;">Contact us</h2>
        <p style="text-align: left;">Please contact the team leader <a href="mailto:03774@qust.edu.cn">Xin Wang (03774@qust.edu.cn)</a> with any questions or interest in collaboration.</p>
        <br>
        <img src="QRCode.png" width="300" alt="QR Code">
    </div>
</body>
</html>
